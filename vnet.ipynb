{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from tqdm import tqdm\n",
    "from visualization import all_axes, og_slice, rs_slice\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imshow\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv3D, Conv3DTranspose, PReLU, MaxPool3D\n",
    "#from keras.layers.pooling import MaxPooling3D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from tensorflow.keras.layers import Concatenate, Add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.nn import conv3d_transpose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and Load Training/Mask Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_np_volume_from_sitk(sitk_img):\n",
    "    trans = (2, 1, 0)\n",
    "    px_spacing = sitk_img.GetSpacing()\n",
    "    img_position = sitk_img.GetOrigin()\n",
    "    np_img = sitk.GetArrayFromImage(sitk_img)\n",
    "    np_img = np.transpose(np_img, trans)\n",
    "    return np_img, px_spacing, img_position\n",
    "\n",
    "\n",
    "ids = []\n",
    "img_count = 0\n",
    "\n",
    "dir_path = \"./hecktor_train/hecktor_nii/\"\n",
    "bb_path = './hecktor_train/bbox.csv'\n",
    "bb_dict = pd.read_csv(bb_path).set_index('PatientID')\n",
    "\n",
    "id_path = os.listdir(dir_path)\n",
    "\n",
    "for _id in id_path:\n",
    "    if str(_id) != \".DS_Store\":\n",
    "        ids.append(_id)\n",
    "\n",
    "ids=ids[:55]        \n",
    "        \n",
    "X = np.zeros((len(ids), 96, 96, 96))\n",
    "y = np.zeros((len(ids), 96, 96, 96))\n",
    "\n",
    "for _id in tqdm(ids):\n",
    "    ct_path = dir_path + _id + \"/\" + _id + \"_ct.nii.gz\"\n",
    "    gt_path = dir_path + _id + \"/\" + _id + \"_ct_gtvt.nii.gz\"\n",
    "\n",
    "    ct_img, spacing, origin = get_np_volume_from_sitk(sitk.ReadImage(ct_path))\n",
    "    gt_img, spacing, origin = get_np_volume_from_sitk(sitk.ReadImage(gt_path))\n",
    "\n",
    "    bb = np.round((np.asarray([\n",
    "    bb_dict.loc[_id, 'x1'],\n",
    "    bb_dict.loc[_id, 'y1'],\n",
    "    bb_dict.loc[_id, 'z1'],\n",
    "    bb_dict.loc[_id, 'x2'],\n",
    "    bb_dict.loc[_id, 'y2'],\n",
    "    bb_dict.loc[_id, 'z2']\n",
    "    ]) - np.tile(origin, 2)) / np.tile(spacing, 2)).astype(int) \n",
    "    \n",
    "    ct_img = ct_img[bb[0]:bb[3], bb[1]:bb[4], bb[2]:bb[5]]\n",
    "    gt_img = gt_img[bb[0]:bb[3], bb[1]:bb[4], bb[2]:bb[5]]\n",
    "    \n",
    "    ct_img = resize(ct_img, (96, 96, 96), mode=\"constant\", preserve_range=True)\n",
    "    gt_img = resize(gt_img, (96, 96, 96), mode=\"constant\", preserve_range=True)\n",
    "\n",
    "    X[img_count, :, :, :] = ct_img\n",
    "    y[img_count, :, :, :] = gt_img\n",
    "\n",
    "    img_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "X = (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=K.expand_dims(X,-1)\n",
    "y=K.expand_dims(y,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:10,:,:,:,:]\n",
    "y = y[0:10,:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    sum_y_true = K.sum(y_true_f)\n",
    "    sum_y_pred = K.sum(y_pred_f)\n",
    "    \n",
    "    return ((2. * intersection + 1.) / (sum_y_true + sum_y_pred + 1.))\n",
    "\n",
    "\n",
    "def dice_coef_mod(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    dice_coefficient_list = []\n",
    "    thresholds = [.5]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_true_binary = tf.where(y_true_f > threshold, tf.ones_like(y_true_f), tf.zeros_like(y_true_f))\n",
    "        y_pred_binary = tf.where(y_pred_f > threshold, tf.ones_like(y_pred_f), tf.zeros_like(y_pred_f))\n",
    "        intersection = K.sum(y_true_binary * y_pred_binary)\n",
    "        dice_coefficient = (2. * intersection + smooth) / (K.sum(y_true_binary) + K.sum(y_pred_binary) + smooth)\n",
    "        dice_coefficient_list.append(dice_coefficient)\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    for i in range(len(dice_coefficient_list)):\n",
    "        total += dice_coefficient_list[i]\n",
    "        \n",
    "    average = total / len(dice_coefficient_list)\n",
    "    \n",
    "    return average\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return (1-dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_net():\n",
    "    input_img = Input((96, 96, 96, 1))\n",
    "\n",
    "    # Layer 1\n",
    "    conv1 = Conv3D(16, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (input_img)\n",
    "    conv1 = PReLU() (conv1)\n",
    "    input1 = Concatenate(axis=-1) (16 * [input_img])\n",
    "    add1 = Add() ([input1, conv1])\n",
    "    down1 = Conv3D(32, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add1)\n",
    "    down1 = PReLU() (down1)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = Conv3D(32, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (down1)\n",
    "    conv2 = PReLU() (conv2)\n",
    "    conv2 = Conv3D(32, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv2)\n",
    "    conv2 = PReLU() (conv2)\n",
    "    add2 = Add() ([conv2, down1])\n",
    "    down2 = Conv3D(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add2)\n",
    "    down2 = PReLU() (down2)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = Conv3D(64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (down2)\n",
    "    conv3 = PReLU() (conv3)\n",
    "    conv3 = Conv3D(64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv3)\n",
    "    conv3 = PReLU() (conv3)\n",
    "    conv3 = Conv3D(64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv3)\n",
    "    conv3 = PReLU() (conv3)\n",
    "    add3 = Add() ([conv3, down2])\n",
    "    down3 = Conv3D(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add3)\n",
    "    down3 = PReLU() (down3)\n",
    "\n",
    "    # Layer 4\n",
    "    conv4 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (down3)\n",
    "    conv4 = PReLU() (conv4)\n",
    "    conv4 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv4)\n",
    "    conv4 = PReLU() (conv4)\n",
    "    conv4 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv4)\n",
    "    conv4 = PReLU() (conv4)\n",
    "    add4 = Add() ([conv4, down3])\n",
    "    down4 = Conv3D(256, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add4)\n",
    "    down4 = PReLU() (down4)\n",
    "\n",
    "    # Layer 5\n",
    "    conv5 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (down4)\n",
    "    conv5 = PReLU() (conv5)\n",
    "    conv5 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv5)\n",
    "    conv5 = PReLU() (conv5)\n",
    "    conv5 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv5)\n",
    "    conv5 = PReLU() (conv5)\n",
    "    add5 = Add() ([conv5, down4])\n",
    "    up5 = Conv3DTranspose(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add5)\n",
    "    up5 = PReLU() (up5)\n",
    "\n",
    "    # Layer 6\n",
    "    skipcon6 = Concatenate(axis=4) ([up5, add4])\n",
    "    conv6 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (skipcon6)\n",
    "    conv6 = PReLU() (conv6)\n",
    "    conv6 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv6)\n",
    "    conv6 = PReLU() (conv6)\n",
    "    conv6 = Conv3D(256, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv6)\n",
    "    conv6 = PReLU() (conv6)\n",
    "    add6 = Add() ([conv6, skipcon6])\n",
    "    up6 = Conv3DTranspose(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add6)\n",
    "    up6 = PReLU() (up6)\n",
    "\n",
    "    # Layer 7\n",
    "    skipcon7 = Concatenate(axis=4) ([up6, add3])\n",
    "    conv7 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (skipcon7)\n",
    "    conv7 = PReLU() (conv7)\n",
    "    conv7 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv7)\n",
    "    conv7 = PReLU() (conv7)\n",
    "    conv7 = Conv3D(128, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv7)\n",
    "    conv7 = PReLU() (conv7)\n",
    "    add7 = Add() ([conv7, skipcon7])\n",
    "    up7 = Conv3DTranspose(32, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add7)\n",
    "    up7 = PReLU() (up7)\n",
    "\n",
    "    # Layer 8\n",
    "    skipcon8 = Concatenate(axis=4) ([up7, add2])\n",
    "    conv8 = Conv3D(64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (skipcon8)\n",
    "    conv8 = PReLU() (conv8)\n",
    "    conv8 = Conv3D(64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (conv8)\n",
    "    conv8 = PReLU() (conv8)\n",
    "    add8 = Add() ([conv8, skipcon8])\n",
    "    up8 = Conv3DTranspose(16, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", activation='relu') (add8)\n",
    "    up8 = PReLU() (up8)\n",
    "\n",
    "    # Layer 9\n",
    "    skipcon9 = Concatenate(axis=4) ([up8, add1])\n",
    "    conv9 = Conv3D(32, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (skipcon9)\n",
    "    conv9 = PReLU() (conv9)\n",
    "    add9 = Add() ([conv9, skipcon9])\n",
    "    conv9 = Conv3D(1, kernel_size=1, padding=\"same\", kernel_initializer=\"he_normal\", activation='relu') (add9)\n",
    "    conv9 = PReLU() (conv9)\n",
    "\n",
    "    sigmoid = Conv3D(1, kernel_size=1, padding=\"same\", kernel_initializer=\"he_normal\", activation='sigmoid') (conv9)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=sigmoid)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=v_net()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=tf.keras.losses.MeanAbsoluteError(), metrics=[dice_coef, dice_coef_mod, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "history = model.fit(y, y, batch_size=1, epochs=50, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_layer, filters, kernel_size):\n",
    "    c = Conv3D(filters, kernel_size = (kernel_size, kernel_size, kernel_size), padding = 'same') (input_layer)\n",
    "    c = BatchNormalization() (c)\n",
    "    c = Activation('relu') (c)\n",
    "    c = Conv3D(filters, kernel_size = (kernel_size, kernel_size, kernel_size), padding = 'same') (c)\n",
    "    c = BatchNormalization() (c)\n",
    "    c = Activation('relu') (c)\n",
    "    c = add([input_layer, c])\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "def v_net(input_img, filters = 8, dropout = 0.2):\n",
    "    c1 = Conv3D(filters, kernel_size = (5, 5, 5), padding = 'same') (input_img)\n",
    "    \n",
    "    c2 = Conv3D(filters*2, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (c1)\n",
    "    c2 = conv_block(c2, filters*2, 5)\n",
    "    \n",
    "    c3 = Conv3D(filters*4, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (c2)\n",
    "    c3 = Dropout(dropout) (c3)\n",
    "    c3 = conv_block(c3, filters*4, 5)\n",
    "    \n",
    "    c4 = Conv3D(filters*8, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (c3)\n",
    "    c4 = Dropout(dropout) (c4)\n",
    "    c4 = conv_block(c4, filters*8, 5)\n",
    "    \n",
    "    c5 = Conv3D(filters*16, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (c4)\n",
    "    c5 = Dropout(dropout) (c5)\n",
    "    c5 = conv_block(c5, filters*16, 5)\n",
    "    \n",
    "    u6 = Conv3DTranspose(filters*8, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = conv_block(u6, filters*16, 5)\n",
    "    u6 = Dropout(dropout) (u6)\n",
    "    \n",
    "    u7 = Conv3DTranspose(filters*4, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (u6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = conv_block(u7, filters*8, 5)\n",
    "    u7 = Dropout(dropout) (u7) \n",
    "    \n",
    "    u8 = Conv3DTranspose(filters*2, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (u7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = conv_block(u8, filters*4, 5)\n",
    "    u8 = Dropout(dropout) (u8) \n",
    "    \n",
    "    u9 = Conv3DTranspose(filters, kernel_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (u8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    \n",
    "    c9 = Conv3D(filters*2, kernel_size = (5, 5, 5), padding = 'same') (u9)\n",
    "    c9 = Dropout(dropout) (c9)\n",
    "    c9 = add([c9, u9])\n",
    "    \n",
    "    outputs = Conv3D(1, kernel_size = (1, 1, 1), activation = 'softmax') (c9)\n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X[1:2,:,:,:,:],y[1:2,:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_temp[0:1,:,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[1,40,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.predict(X[1:2,:,:,:,0])[0,60,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.amax(model.predict(X[0:1,:,:,:,:])[0,80,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.amax(X[0:1,80,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_indices = np.random.choice(201, size=10, replace=False)\n",
    "#random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X[random_indices, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y[random_indices, :, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_axes(\"CHGJ007\", -30, 100, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_slice(\"CHGJ007\", 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs_slice(\"CHGJ007\", 32, 128, 128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def conv_block(input_layer, filters, kernel_size):\n",
    "    c = Conv3D(filters, kernel_size = (kernel_size, kernel_size, kernel_size), padding = 'same') (input_layer)\n",
    "    c = BatchNormalization() (c)\n",
    "    c = Activation('relu') (c)\n",
    "    c = Conv3D(filters, kernel_size = (kernel_size, kernel_size, kernel_size), padding = 'same') (c)\n",
    "    c = BatchNormalization() (c)\n",
    "    c = Activation('relu') (c)\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "def v_net(input_img, n_filters = 8, dropout = 0.2):\n",
    "    c1 = conv_block(input_img,n_filters,3)\n",
    "    p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv_block(p1,n_filters*2,3);\n",
    "    p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv_block(p2,n_filters*4,3);\n",
    "    p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv_block(p3,n_filters*8,3);\n",
    "    p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv_block(p4,n_filters*16,3);\n",
    "    \n",
    "    u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c5);\n",
    "    u6 = concatenate([u6,c4]);\n",
    "    \n",
    "    c6 = conv_block(u6,n_filters*8,3)\n",
    "    c6 = Dropout(dropout)(c6)\n",
    "    \n",
    "    u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);\n",
    "    u7 = concatenate([u7,c3]);\n",
    "    c7 = conv_block(u7,n_filters*4,3)\n",
    "    c7 = Dropout(dropout)(c7)\n",
    "    \n",
    "    u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);\n",
    "    u8 = concatenate([u8,c2]);\n",
    "    \n",
    "    c8 = conv_block(u8,n_filters*2,3)\n",
    "    c8 = Dropout(dropout)(c8)\n",
    "    \n",
    "    u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);\n",
    "    u9 = concatenate([u9,c1]);\n",
    "    c9 = conv_block(u9,n_filters,3)\n",
    "    \n",
    "    outputs = Conv3D(1, (1,1,1), activation='softmax')(c9)\n",
    "    \n",
    "    print(\"!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(outputs.shape)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=outputs)\n",
    "    \n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.inf)\n",
    "#print(X[200][70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''per_dic = {}\n",
    "\n",
    "per_dic['loss']=history.history['loss']    \n",
    "per_dic['dice_coef']=history.history['dice_coef']    \n",
    "per_dic['dice_coef_mod']=history.history['dice_coef_mod'] \n",
    "per_dic['precision']=history.history['precision_3'] \n",
    "per_dic['recall']=history.history['recall_3'] \n",
    "per_dic['val_loss']=history.history['val_loss']\n",
    "per_dic['val_dice_coef']=history.history['val_dice_coef']\n",
    "per_dic['val_dice_coef_mod']=history.history['val_dice_coef_mod']\n",
    "per_dic['val_precision']=history.history['val_precision_3']\n",
    "per_dic['val_recall']=history.history['val_recall_3']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = pd.DataFrame.from_dict(per_dic)\n",
    "\n",
    "#with pd.ExcelWriter('MAE peformance.xlsx') as writer:  \n",
    "    #p.to_excel(writer, sheet_name='performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = model.predict(X)\n",
    "#score = model.evaluate(X, y, verbose=0, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''kf = KFold(n_splits=5)\n",
    "performance = {}\n",
    "k = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index, :, :, :], X[test_index, :, :, :]\n",
    "    y_train, y_test = y[train_index, :, :, :], y[test_index, :, :, :]\n",
    "    \n",
    "    model = v_net()\n",
    "    start = time()\n",
    "    history = model.fit(X_train, y_train, batch_size=1, epochs=20 , validation_split=0.3)\n",
    "    elapsed = (time()-start)/60\n",
    "    score = model.evaluate(X_test, y_test, verbose=0, batch_size=1)\n",
    "    \n",
    "    per_dic = {}\n",
    "    per_dic['Testdiceloss']=history.history['val_loss']    \n",
    "    per_dic['Testdsc']=score[1]   \n",
    "    per_dic['Testprec']=score[2]\n",
    "    per_dic['Testrec']=score[3]       \n",
    "    per_dic['elapsed_minutes']=elapsed \n",
    "    performance[k]=per_dic\n",
    "    \n",
    "    k += 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''p1 = pd.DataFrame.from_dict(performance[1])\n",
    "p2 = pd.DataFrame.from_dict(performance[2])\n",
    "p3 = pd.DataFrame.from_dict(performance[3])\n",
    "p4 = pd.DataFrame.from_dict(performance[4])\n",
    "p5 = pd.DataFrame.from_dict(performance[5])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with pd.ExcelWriter('model peformance.xlsx') as writer:  \n",
    "    p1.to_excel(writer, sheet_name='k1')\n",
    "    p2.to_excel(writer, sheet_name='k2')\n",
    "    p3.to_excel(writer, sheet_name='k3')\n",
    "    p4.to_excel(writer, sheet_name='k4')\n",
    "    p5.to_excel(writer, sheet_name='k5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "0.0001\n",
      "0.001\n",
      "0.01\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "rates=[1,0.01,0.001,0.0001,0.00001]\n",
    "for exp in range(-5, 0):\n",
    "    print(10**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_index=[]\n",
    "for i in range(0, 201):\n",
    "    for j in range(0, 96):\n",
    "        patient_index.append(i)\n",
    "patient_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 0, 9, 9, 4, 0, 8, 6, 4, 8, 9, 8, 2, 8, 1, 9, 5, 9, 9, 1, 2,\n",
       "       8, 3, 4, 8, 9, 7, 7, 8, 2, 3, 9, 9, 5, 2, 4, 2, 0, 1, 4, 2, 6, 1,\n",
       "       4, 3, 9, 0, 4, 5, 8, 2, 5, 0, 1, 6, 0, 8, 1, 5, 8, 7, 8, 9, 9, 0,\n",
       "       5, 4, 8, 7, 4, 2, 7, 8, 0, 2, 5, 2, 4, 6, 1, 2, 7, 6, 7, 1, 7, 7,\n",
       "       2, 1, 6, 0, 6, 5, 9, 0, 3, 3, 4, 3, 2, 0, 8, 1, 9, 4, 5, 6, 7, 7,\n",
       "       4, 4, 8, 9, 2, 1, 1, 7, 1, 8, 7, 1, 4, 0, 1, 3, 1, 7, 0, 1, 3, 1,\n",
       "       0, 3, 5, 9, 3, 7, 9, 8, 9, 6, 4, 5, 0, 4, 5, 1, 7, 5, 8, 9, 4, 9,\n",
       "       6, 9, 6, 2, 3, 9, 2, 3, 8, 0, 0, 0, 5, 2, 2, 7, 0, 8, 7, 9, 5, 3,\n",
       "       6, 5, 7, 8, 8, 2, 9, 9, 8, 3, 1, 0, 8, 5, 6, 1, 9, 0, 2, 8, 9, 8,\n",
       "       0, 5, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_list = np.random.randint(10,size=201)\n",
    "random_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
